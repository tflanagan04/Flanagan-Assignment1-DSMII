{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51768980",
   "metadata": {},
   "source": [
    "# Assignment 1: Predicting Employee Attrition with Random Forests\n",
    "\n",
    "Execute cells **top to bottom**. Where you see `# TODO`, add your code.\n",
    "\n",
    "**Data:** `data/IBM_HR_Employee_Attrition.csv`\n",
    "\n",
    "**Deliverables produced in this file:**\n",
    "- Baseline Decision Tree metrics (accuracy, precision, recall)\n",
    "- Random Forest metrics + side-by-side comparison table\n",
    "- Feature importance visualization\n",
    "- Markdown sections for **Key Drivers of Attrition** and **Reflection**\n",
    "\n",
    "### Download Dependencies\n",
    "Run this cell once to install all dependencies. These can also be run directly in the terminal if you prefer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89f687",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdf3a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing required libraries...\n",
      "✓ All libraries imported successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing required libraries...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27a7b9",
   "metadata": {},
   "source": [
    "### Step 1: Load the dataset\n",
    "----------------------------------------------------------------------------\n",
    "Confirm the CSV can be read and preview the first rows. The following code should output the first 5 rows of the IBM HR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15b8b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading employee attrition dataset...\n",
      "✓ Dataset loaded successfully!\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
      "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
      "1   49        No  Travel_Frequently        279  Research & Development   \n",
      "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
      "3   33        No  Travel_Frequently       1392  Research & Development   \n",
      "4   27        No      Travel_Rarely        591  Research & Development   \n",
      "\n",
      "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
      "0                 1          2  Life Sciences              1               1   \n",
      "1                 8          1  Life Sciences              1               2   \n",
      "2                 2          2          Other              1               4   \n",
      "3                 3          4  Life Sciences              1               5   \n",
      "4                 2          1        Medical              1               7   \n",
      "\n",
      "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
      "0  ...                         1            80                 0   \n",
      "1  ...                         4            80                 1   \n",
      "2  ...                         2            80                 0   \n",
      "3  ...                         3            80                 0   \n",
      "4  ...                         4            80                 1   \n",
      "\n",
      "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
      "0                  8                      0               1               6   \n",
      "1                 10                      3               3              10   \n",
      "2                  7                      3               3               0   \n",
      "3                  8                      3               3               8   \n",
      "4                  6                      3               3               2   \n",
      "\n",
      "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
      "0                  4                        0                     5  \n",
      "1                  7                        1                     7  \n",
      "2                  0                        0                     0  \n",
      "3                  7                        3                     0  \n",
      "4                  2                        2                     2  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n",
      "None\n",
      "\n",
      "================================================================================\n",
      "CHECKPOINT: Verify that the dataset loaded correctly and you can see column names\n",
      "Dataset shape: 1470 rows, 35 columns\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading employee attrition dataset...\")\n",
    "df = pd.read_csv('./data/IBM_HR_Employee_Attrition.csv')\n",
    "print(\"✓ Dataset loaded successfully!\\n\")\n",
    "\n",
    "# Display first few rows to verify load\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: Verify that the dataset loaded correctly and you can see column names\")\n",
    "print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2eff4d",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Prepare the Dataset\n",
    "----------------------------------------------------------------------------\n",
    "Perform the same kind of exploratory analysis real data scientists do before building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3efa6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CHECKPOINT: X_cleaned should have all numeric columns, y should contain Attrition values\n",
      "X_cleaned shape: Not yet defined\n",
      "y shape: Not yet defined\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "# TODO: Use df.describe() and df.info() to generate summary statistics for numeric features\n",
    "\n",
    "\n",
    "# Plot attrition counts to see class imbalance\n",
    "# TODO: Use df['Attrition'].value_counts() and create a visualization using matplotlib to see how imbalanced the dataset is\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "# TODO: Use pd.get_dummies() to encode categorical variables\n",
    "# Store the result in a variable (you'll need this for the next step)\n",
    "\n",
    "\n",
    "# Split features (X) from target (y)\n",
    "# TODO: Create X_cleaned with all columns except 'Attrition'\n",
    "# TODO: Create y with just the 'Attrition' column\n",
    "X_cleaned = None  # Replace with your feature matrix\n",
    "y = None  # Replace with your target variable\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT: X_cleaned should have all numeric columns, y should contain Attrition values\")\n",
    "print(f\"X_cleaned shape: {X_cleaned.shape if X_cleaned is not None else 'Not yet defined'}\")\n",
    "print(f\"y shape: {y.shape if y is not None else 'Not yet defined'}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c4110",
   "metadata": {},
   "source": [
    "### Step 3: Train a Baseline Decision Tree Model\n",
    "----------------------------------------------------------------------------\n",
    "Build a baseline decision tree for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ecb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "# TODO: Use train_test_split with test_size=0.2, random_state=42, stratify=y\n",
    "X_train, X_test, y_train, y_test = None, None, None, None  # Replace with train_test_split()\n",
    "\n",
    "# Train a decision tree classifier\n",
    "# TODO: Initialize DecisionTreeClassifier(random_state=42)\n",
    "dt_model = None  # Replace with DecisionTreeClassifier\n",
    "\n",
    "# TODO: Fit the model on training data\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "# TODO: Use dt_model.predict() on X_test\n",
    "dt_predictions = None  # Replace with predictions\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "# TODO: Calculate accuracy, precision, and recall for the decision tree\n",
    "dt_accuracy = None  # Replace with accuracy_score()\n",
    "dt_precision = None  # Replace with precision_score()\n",
    "dt_recall = None  # Replace with recall_score()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE DECISION TREE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "# TODO: Print accuracy, precision, and recall with clear labels\n",
    "print(f\"Accuracy: {dt_accuracy if dt_accuracy is not None else 'Not yet calculated'}\")\n",
    "print(f\"Precision: {dt_precision if dt_precision is not None else 'Not yet calculated'}\")\n",
    "print(f\"Recall: {dt_recall if dt_recall is not None else 'Not yet calculated'}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9235c65",
   "metadata": {},
   "source": [
    "### Step 4: Build and Evaluate a Random Forest Model\n",
    "----------------------------------------------------------------------------\n",
    "Move beyond a single tree to a more powerful ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move beyond a single tree to a more powerful ensemble model\n",
    "\n",
    "# Train a random forest classifier\n",
    "# TODO: Initialize and train a RandomForestClassifier with these parameters:\n",
    "# n_estimators=200, max_depth=None, min_samples_split=10, min_samples_leaf=2,\n",
    "# max_features='sqrt', class_weight='balanced', random_state=42\n",
    "rf_model = None  # Replace with trained RandomForestClassifier\n",
    "\n",
    "# Make predictions using probability threshold\n",
    "# TODO: Use rf_model.predict_proba() to get probabilities for the positive class\n",
    "# TODO: Apply a threshold of 0.35 to convert probabilities to predictions\n",
    "# (rf_probabilities >= 0.35).astype(int)\n",
    "rf_predictions = None  # Replace with threshold-adjusted predictions\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "# TODO: Calculate accuracy, precision, and recall for the random forest\n",
    "rf_accuracy = None  # Replace with accuracy_score()\n",
    "rf_precision = None  # Replace with precision_score()\n",
    "rf_recall = None  # Replace with recall_score()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy: {rf_accuracy if rf_accuracy is not None else 'Not yet calculated'}\")\n",
    "print(f\"Precision: {rf_precision if rf_precision is not None else 'Not yet calculated'}\")\n",
    "print(f\"Recall: {rf_recall if rf_recall is not None else 'Not yet calculated'}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create comparison table\n",
    "# TODO: Create a pandas DataFrame comparing both models side-by-side\n",
    "# Columns: Model, Accuracy, Precision, Recall\n",
    "model_comparison = None  # Replace with DataFrame\n",
    "\n",
    "# TODO: Display the comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "# Display table here\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35025fac",
   "metadata": {},
   "source": [
    "### Step 5: Interpret Feature Importances\n",
    "----------------------------------------------------------------------------\n",
    "Turn model results into actionable insights for HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a34998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "# TODO: Get feature_importances_ from rf_model and create a pandas Series\n",
    "# with feature names as index\n",
    "feature_importances = None  # Replace with Series of importances\n",
    "\n",
    "# TODO: Sort feature importances in descending order\n",
    "\n",
    "\n",
    "# TODO: Get top 10 most important features\n",
    "top_10_features = None  # Replace with top 10\n",
    "\n",
    "# Visualize top 10 feature importances\n",
    "# TODO: Create a horizontal bar plot of the top 10 features\n",
    "# Use plt.barh() or top_10_features.plot(kind='barh')\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY DRIVERS OF ATTRITION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b0f8f",
   "metadata": {},
   "source": [
    "#### Key Drivers of Attrition\n",
    "Write 3-5 bullet points explaining what the top factors reveal. Include at least one actionable takeaway for HR\n",
    "- [Your insight 1]\n",
    "- [Your insight 2]\n",
    "- [Your insight 3]\n",
    "- [Actionable takeaway for HR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe322d",
   "metadata": {},
   "source": [
    "### Step 6: Reflection (150-200 words)\n",
    "----------------------------------------------------------------------------\n",
    "Write a 150-200 word reflection addressing:\n",
    "- How the random forest improved upon the decision tree baseline\n",
    "- When ensemble methods are worth the added complexity\n",
    "- How these modeling skills connect to your final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191570f2",
   "metadata": {},
   "source": [
    "[Write your reflection here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e475dfb",
   "metadata": {},
   "source": [
    "### Step 7: Push to GitHub\n",
    "----------------------------------------------------------------------------\n",
    "Once complete, save and push your work:\n",
    "1. Save this file\n",
    "2. Run in terminal:\n",
    "```sh\n",
    "git add .\n",
    "git commit -m 'completed employee attrition assignment'\n",
    "git push\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
